---
title: '9. Three-Factor ANOVA'
subtitle: "Mark Hurlstone, Richard Philpot"
order: 10
---


# Lecture

Watch Part 1 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=2022872)

Watch Part 2 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=2022874)

Watch Part 3 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=2023033)

Download the lecture slides [here](data/Wk9/Three-Factor ANOVA HANDOUT.pdf), and [here](data/Wk9/Three-Factor ANOVA.pdf) for a larger version.

# Lab

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>
<br>

> *I judge you unfortunate because you have never lived through misfortune. You have passed through life without an opponent---no one can ever know what you are capable of, not even you. ---Seneca*

![Seneca](images/Seneca.png){width=50%}


## Learning Objectives
In this week's lecture, we introduced the procedures involved in interpreting a three-factor ANOVA. Specifically, what to do in the event that the three-way interaction is significant. We saw that the simplest strategy in this instance is to re-analyse the data as a series of two-factor ANOVAs. In today's lab session, we will demonstrate how to perform a three-factor fully within-participants and mixed ANOVA in R (using the two hypothetical data sets presented in the lecture), and how to analyze a three-way interaction using the procedures described in the lecture. **In this lab session, I am also going to show you a better way of rounding the values in dataframes than the `options(digits = )` command used in earlier lab sessions.**

**If you get stuck at any point, be proactive and ask for help from one of the GTAs.**

## Getting Started

{{< include /Includes/_login.qmd >}}


Once you are logged into the server, create a folder for today's session. Navigate to the bottom right panel and under the `Files` option select the `New Folder` option. Name the new folder `psyc214_lab_9`. **Please ensure that you spell this correctly** otherwise when you set the directory using the command given below it will return an error.   

Se we can save this session on the server, click `File` on the top ribbon and select `New project`. Next, select existing directory and name the working directory `~/psyc214_lab_9` before selecting `create project`.

Finally, open a script for executing today's coding exercises. Navigate to the top left pane of RStudio, select `File` -> `New File` -> `R Script`. Working from a script will make it easier to edit your code and you will be able to save your work for a later date. 

![](images/RScript.png){width=75%}

Let's set our working directory:

```{r eval = FALSE}
setwd("~/psyc214_lab_9")
```

Now that you have created a folder for today's session, it’s time to add the Week 9 files. Download the files and data needed from [here](data/wk9/psyc214_lab_9.zip) and upload to the folder `psyc214_lab_9`.

Before moving on, let's load the relevant libraries that we will be using in today's session.

```{r, message = FALSE, eval=FALSE}
library("tidyverse")  # For data storage and manipulation
library("tidyr")      # For tidy data
library("rstatix")    # For descriptives statistics, outlier detection, running the ANOVAs etc.
source("simple.R")    # Custom function for generating the simple main effects
```

```{r, echo = FALSE, message=FALSE}
library("tidyverse")  # For data storage and manipulation
library("tidyr")      # For tidy data
library("rstatix")    # For descriptives statistics, outlier detection, running the ANOVAs etc.
source("data/Wk9/simple.R")    # Custom function for generating the simple main effects
```

# Today's Lab Activities

## Analysing the hypothetical data for the memory and context study

A memory researcher wants to know if memory is better when material is tested in the same context it was learned in. The researcher also wants to know whether recall and recognition memory are equally context dependent. The researcher manipulates three factors in a 2 $\times$ 2 $\times$ 2 fully within-participants design:

* **memory task** (recall *vs.* recognition) 

* **learning context** (learn underwater *vs.* learn land) 

* **testing context** (test underwater *vs.* test land)

Participants are given words to remember in a specific learning context (either under water or on land) and are then tested in either the same context (e.g., under water if the words were learned under water) or a different context (e.g., on land if the words were learned under water). Memory is tested using a recall procedure (by asking participants to recall the studied words) or a recognition procedure (by presenting participants with a list of words and asking them to indicate which they had studied previously). The dependent measure is the number of words remembered correctly. 

The data set contains the following variables:

* **Participant:** represents the participant number, which ranges from 1--5. 

* **Recall_Under_Under:** the number of words *recalled* correctly when material was learned under water and tested under water.	

* **Recall_Under_Land:** the number of words *recalled* correctly when material was learned under water and tested on land.		

* **Recall_Land_Under:** the number of words *recalled* correctly when material was learned on land and tested under water.		

* **Recall_Land_Land:**	the number of words *recalled* correctly when material was learned on land and tested on land.		

* **Recognition_Under_Under:**	the number of words *recognised* correctly when material was learned under water and tested under water.	

* **Recognition_Under_Land:** the number of words *recognised* correctly when material was learned under water and tested on land.	

* **Recognition_Land_Under:** the number of words *recognised* correctly when material was learned on land and tested under water.

* **Recognition_Land_Land:** the number of words *recognised* correctly when material was learned on land and tested on land.		

### Import data, set variables as factors, and generate descriptive statistics

The first thing you need to do is load the data into RStudio. Make sure that you name your data frame as `memoryContext`. 

```{r}
# *** ENTER YOUR OWN CODE HERE TO IMPORT THE DATA ***
```

```{r, echo = FALSE, eval = FALSE}
# Import the data
memoryContext = read_csv("memoryContext.csv")
# Print the dataframe
(memoryContext)
```

```{r, echo = FALSE, message = FALSE}
# Import the data
memoryContext = read_csv("data/Wk9/memoryContext.csv")
# Print the dataframe
(memoryContext)
```

The next thing we need to do is convert our data from wide format into long format. The first thing we need to do is group the columns `Recall_Under_Under` through to `Recognition_Land_Land` into a new variable called `Group` using the `gather()` function:

```{r, echo = TRUE, message = FALSE}
# Gather factors into a single column
memoryContextLong = memoryContext %>%
  gather(Group,Accuracy,Recall_Under_Under:Recognition_Land_Land,factor_key = TRUE)
(memoryContextLong)
```

This function was explained in the previous lab session, so if it is not clear what is going on here, check the Week 8 lab session materials.

Looking at the new data frame we have created, we can see that it is not exactly what we want. Our new variable `Group` actually contains three independent variables. What we want is to separate these independent variables into three separate columns: `MemoryTask`, `LearningContext`, and `TestingContext`. We can do that with the `separate()` function:

```{r, echo = TRUE, message = FALSE}
# Now separate the variable "Group" into separate columns for each factor
memoryContextLongSep = memoryContextLong %>%
  separate(Group, c("MemoryTask","LearningContext","TestingContext"))
(memoryContextLongSep)
```

Again, this function was explained in the previous lab session, so if it is not clear what is going on here, check the Week 8 lab session materials. The latest version of the data set is named `memoryContextLongSep`, so make sure you use this from henceforth.

The next thing we need to do is convert the variables `Participant`, `MemoryTask`, `LearningContext`, and `TestingContext` into factors and re-order the levels of the latter two variables:

```{r, echo = TRUE, message = FALSE}
# Make sure all necessary variables are coded as factors -- re-order the levels of "LearningContext" and "TestingContext"
memoryContextLongSep$Participant = factor(memoryContextLongSep$Participant)
memoryContextLongSep$MemoryTask = factor(memoryContextLongSep$MemoryTask)
memoryContextLongSep$LearningContext = factor(memoryContextLongSep$LearningContext,levels = c("Under","Land"))
memoryContextLongSep$TestingContext = factor(memoryContextLongSep$TestingContext,levels = c("Under","Land"))
```

Next, we will generate some descriptive statistics (mean and standard deviation):

```{r, echo = TRUE, message = FALSE}
# Get descriptive statistics
descriptives = memoryContextLongSep %>%
  # Organise the output by the "MemoryTask", "LearningContext", and "TestingContext" factors
  group_by(MemoryTask, LearningContext, TestingContext) %>%
  # Request means, standard deviations, and confidence intervals
  get_summary_stats(Accuracy, show = c("mean", "sd"))
  # Round the statistics to two decimal places
  descriptives$mean = round(descriptives$mean, 2)
  descriptives$sd = round(descriptives$sd, 2)
  # Print the results
  print.data.frame(descriptives)
```

Notice the code we have added to round the descriptive statistics to two-decimal places. We use the function `round()`, specifying how many decimal places we want to round the values (in this case 2). Inside this function, we place the variable we want to be rounded. Because our data are in a dataframe, we need to specify the name of our dataframe followed by a dollar sign and the name of the variable in the dataframe to be rounded (e.g., descriptives\$mean tells R to round the values of the variable `mean` in the dataframe `descriptives`). We also need to re-assign the rounded values to the dataframe, so that the variable gets updated (e.g., that's what the descriptives\$mean = bit does). 

Notice also that our standard deviations have been reported to two decimal places, but our means haven't. Why so? This is because the numbers after the first decimal place in this instance are all zeros, so R doesn't report them. Bearing in mind that APA style requires we report descriptive statistics to two-decimal places, we would just add a single zero to each of the means at the second decimal place. For example, the first mean in the table, 7.6, would be reported as 7.60. 

At this stage, we would ordinarily perform various checks including identifying possible outliers and checking that our data satisfy the normality assumption. However, as per last week, time is limited, so we won't perform those checks today (just remember that ordinarily you should not skip this part!). One assumption that is important in within-participants designs is the sphericity assumption, but remember that this only applies to designs with within-participants factors with three or more levels. All of our factors have two levels, so this assumption is not relevant in this instance (it's also not relevant for our second data set that we analyse later, for which the within-participants factors also only comprise two levels).

### Running the ANOVA, follow-up ANOVAs, and simple main effects

To run our ANOVA, we are going to use the `anova_test` function from the `rstatix` package. This is the same function that we used in the Week 8 lab session to analyse two-factor fully within-participants and mixed designs. The code required to run the ANOVA is given below:

```{r, message = FALSE, warning = FALSE}
# Create the fully within-participants design ANOVA model
memoryContextModel = anova_test(data = memoryContextLongSep, dv = Accuracy, wid = Participant, within = c(MemoryTask, LearningContext, TestingContext), detailed = TRUE)
# Round the p values to three decimal places
memoryContextModel$p = round(memoryContextModel$p, 3)
# Print the model summary
(memoryContextModel)
```

To create the model, the first argument we supplied to `anova_test` was the name of our data, `memoryContextLongSep`. The second argument we supplied was our dependent variable, `Accuracy`. The third argument we supplied was `Participant`, which is the column containing the individuals/participants identifier. The fourth argument we supplied was our within-participants factors, `MemoryTask`, `LearningContext`, and `TestingContext`. 

As we saw in last week's lab session, the resulting ANOVA table is different in format to those given in the lecture, which follow a more conventional style. In the ANOVA tables given in the lecture, each outcome (each main effect and interaction) is given on a separate row, with the error term used to test it given in the row directly beneath it. However, `anova_test` gives each outcome and its associated error term all in the same row. Specifically, the row corresponding to each outcome contains the between-group degrees of freedom (DFn), the error degrees of freedom (DFd), the between-group sums of squares (SSn), the error sums of squares (SSd), the $F$ ratio (F), the *p* (p) value, and the generalised eta squared (ges) value (a measure of effect size). What `anova_test` does not give us is the between-group mean squares and the error mean squares that are used to calculate the $F$ ratios. However, I showed you how to calculate these in last week's lab session if you should ever have need for these (you probably won't).

You might be wondering why `anova_test` has not given us Mauchly's test of sphericity and the Greenhouse-Geisser correction. This is because all of our factors have only two levels, so the sphericity assumption does not apply. Remember, the `anova_test` function only generates these tests and corrections when at least one of the within-participants factors has three or more levels.

Inspecting the ANOVA table, rows two to four give the main effects of Memory Task, Learning Context, and Testing Context; rows five to seven give the Memory Task $\times$ Learning Context, Memory Task $\times$ Testing Context, and Learning Context $\times$ Testing Context two-way interactions; and row eight gives the Memory Task $\times$ Learning Context $\times$ Testing Context three-way interaction. Looking at the *p* values, we can see that there is a significant Learning Context $\times$ Testing Context two-way interaction, $p$ = .006, and a significant Memory Task $\times$ Learning Context $\times$ Testing Context three-way interaction, $p$ = .006.

Because the three-way interaction is significant, we need to analyse it further. As explained in the lecture, a significant three-way interaction occurs when there are different two-way interactions between two of the factors according to the levels of the third factor. The simplest way to analyse a signiﬁcant three-way interaction is to re-analyse it as a series of two-factor ANOVAs. To do this, we first need to decide on a factor that we are going to split the analyses by. We can pick any factor we want, but there is usually one factor that stands out as being an obvious choice and in our case it is the memory task factor. So, what we need to do is to perform two, two-factor ANOVAs:

1. a 2 (learning context: learn under water *vs.* learn land) $\times$ 2 (testing context: test under water *vs.* test land) ANOVA for the *recall* memory test condition only.

2. a 2 (learning context: learn under water *vs.* learn land) $\times$ 2 (testing context: test under water *vs.* test land) ANOVA for the *recognition* memory test condition only.

We will start by running the two-factor ANOVA for the recall memory test condition (ignoring the recognition memory test condition). To do this, we first need to produce a filtered version of our data set called `recallOnly` that only includes the results for the recall memory test condition. We can create that with the following piece of code:

```{r, message = FALSE, warning = FALSE}
# Get the data for the "Recall" condition only
recallOnly = memoryContextLongSep %>%
  filter(MemoryTask == "Recall") 
```

The command `filter(MemoryTask == "Recall")` tells R that we only want the data for the recall condition of the Memory Task factor. 

Next, we can run our two-factor ANOVA on this filtered data set. The steps are the same as above, except that we need to drop the Memory Task factor included previously (remember, we are only analysing the recall condition of the Memory Task factor). 

```{r, message = FALSE, warning = FALSE}
# Run the two-factor ANOVA for the "Recall" condition only
recallModel = anova_test(data = recallOnly, dv = Accuracy, wid = Participant, within = c(LearningContext, TestingContext), detailed = TRUE)
# Round the p values to three decimal places
recallModel$p = round(recallModel$p, 3)
# Print the model summary
(recallModel)
```

The only thing we are interested in from the ANOVA table is the outcome of the two-way interaction between Learning Context and Testing Context; you can ignore everything else. You can see that the interaction is significant, *p* = .001, so the next step is to perform a simple main effects analysis to identify the nature of the interaction.

The procedure for performing the simple main effects analysis is the same as I demonstrated to you in our Week 8 lab session. That is, we use the **pooled error terms** approach, which means that the simple main effects of each factor are calculated using the same error term that was used to test the main effect of that factor in the ANOVA that preceded the simple main effects analysis (in this case, our two-factor ANOVA on the recall data only).

Before we can calculate the simple main effects, there are a few things we need to do. First, we need to store our ANOVA table in a dataframe:

```{r, message=FALSE}
# Get the recall ANOVA table
recallAnovaTable = get_anova_table(recallModel)
```

Next, we need to calculate the cell totals for each of the four conditions and the number of observations (i.e., scores) in each cell:

```{r, message=FALSE}
# Get cell totals and counts
recallCellTotals = recallOnly %>%
  # Organise the output by the "LearningContext" and "TestingContext" factors
  group_by(LearningContext, TestingContext) %>%
  # Request cell totals and number of observations (i.e., scores)
  summarise(sum = sum(Accuracy),n = n())
  # Print the results
  (recallCellTotals)
```

Then, we need to specify which simple main effects we want to generate. We are first going to calculate the simple main effects of the factor Learning Context at Testing Context. This means, we are going to:

* Test the difference between learning under water and learning on land when tested *under water* only.
* Test the difference between learning under water and learning on land when tested *on land* only.

To do this, we need to declare Learning Context as the "fixed" factor (we are always comparing learning under water and learning on land) and Testing Context as the "across" factor (the comparison between learning under water and learning on land occurs "across" the test under water and test on land levels of the Testing Context factor): 

```{r, message=FALSE}
# Create "fixed" and "across" factors
fixed  = "LearningContext"
across = "TestingContext"
```

We then generate the simple main effects of Learning Context by passing these variables into `simple()`:

```{r, message=FALSE}
# Simple main effects of "Learning Context" at "TestingContext"
smeLearningContext = simple(recallCellTotals,recallAnovaTable,fixed,across)
# Round the p values to three decimal places
smeLearningContext$P = round(smeLearningContext$P, 3)
(smeLearningContext)
```

We can see that there is a significant simple main effect of Learning Context at test under water, $p$ = .005; when tested under water, recall memory scores are higher when the material was learned under water than when it was learned on land. There is also a significant simple main effect of Learning Context at test on land, $p$ = .041; when tested on land, recall memory scores are higher when the material was learned on land than when it was learned under water. You will need to consult the descriptive statistics to verify this is correct.

Next, we are going to calculate the simple main effects of the factor Testing Context at Learning Context. This means, we are going to:

* Test the difference between testing under water and testing on land when material was learned *under water* only.
* Test the difference between testing under water and testing on land when material was learned *on land* only.

To do this, we now need to declare Testing Context as the "fixed" factor and Learning Context as the "across" factor: 

```{r, message=FALSE}
# Create "fixed" and "across" factors
fixed  = "TestingContext"
across = "LearningContext"
```

We then generate the simple main effects of Testing Context with the following:

```{r, message=FALSE}
# Simple main effects of "Testing Context" at "LearningContext"
smeTestingContext = simple(recallCellTotals,recallAnovaTable,fixed,across)
# Round the p values to three decimal places
smeTestingContext$P = round(smeTestingContext$P, 3)
(smeTestingContext)
```

We can see that there is a significant simple main effect of Testing Context at learn under water, $p$ = .010; when the material is learned under water, recall memory scores are higher when tested under water than when tested on land. There is also a significant simple main effect of Testing Context at learn land, $p$ = .007; when the material is learned on land, recall memory scores are higher when tested on land than when tested under water.  

In sum, from the simple main effects analysis what we can see is that recall memory is context sensitive; that is, recall memory performance is better when people are tested in the same context that they learned the information than when they are tested in a different context to that which they learned the information.

What about recognition memory?

That brings us to our second two-factor ANOVA. For this, we now need to produce a filtered version of our data set called `recognitionOnly` that only includes the results for the recognition memory task condition. We can create that with the following piece of code:

```{r, message = FALSE, warning = FALSE}
# Get the data for the "Recognition" condition only
recognitionOnly = memoryContextLongSep %>%
  filter(MemoryTask == "Recognition") 
```  

The command `filter(MemoryTask == "Recognition")` tells R that we only want the data for the recognition condition of the Memory Task factor. 

Next, we can run our two-factor ANOVA on this filtered data set.  

```{r, message = FALSE, warning = FALSE}
# Run the two-factor ANOVA for the "Recognition" condition only
recognitionModel = anova_test(data = recognitionOnly, dv = Accuracy, wid = Participant, within = c(LearningContext, TestingContext), detailed = TRUE)
# Round the p values to three decimal places
recognitionModel$p = round(recognitionModel$p, 3)
# Print the model summary
(recognitionModel)
```

The key result is that this time the critical two-way interaction is nonsignificant, *p* = 0.553. What this indicates is that, unlike recall memory, recognition memory is not context sensitive. This is the reason for the three-way interaction; recall memory is sensitive to the learning and testing context, whereas recognition memory is apparently insensitive to the learning and testing context. 

### Writing up the results

![Figure 1. Memory scores as a function of learning context and testing context for the recall memory task (left panel) and the recognition memory task (right panel).](images/MemoryContextData.png){width=75%}

Figure 1 shows memory scores as a function of learning context and testing context for the recall and recognition memory tasks. These data were subjected to a 2 (memory task: recall *vs.* recognition) $\times$ 2 (learning context: learn under water *vs.* learn land) $\times$ 2 (testing context: test under water *vs.* test land) within-participants ANOVA. There was no significant main effect of memory task, *F*(1, 4) = 1.00, *p* = .374, no significant main effect of learning context, *F*(1, 4) = 1.59, *p* = .276, and no significant main effect of testing context, *F*(1, 4) = 0.01, *p* = .911. Neither the memory task $\times$ learning context interaction, *F*(1, 4) = 2.95, *p* = .161, nor the memory task $\times$ testing context interaction, *F*(1, 4) = 0.71, *p* = .446, were significant. However, the learning context $\times$ testing context interaction was significant, *F*(1, 4) = 27.22, *p* = .006. Critically, there was also a significant three-way interaction, *F*(1,4) = 27.13, *p* = .006.

To explore the three-way interaction, two 2 (learning context) $\times$ 2 (testing context) ANOVAs were conducted; one using the data for the recall memory task only, and the second using the data for the recognition memory task only. For the first ANOVA on the recall memory task data, there was a significant interaction, *F*(1, 4) = 62.06, *p* = .001. A simple main effects analysis revealed that when tested under water, recall memory was better when the material was learned under water than when it was learned on land, *F*(1, 4) = 44.10, *p* = .005, and when tested on land, recall memory was better when the material was learned on land than when it was learned under water, *F*(1, 4) = 12.10, *p* = .041. Mirroring these results, when the material was learned under water, recall memory was better when tested under water than when tested on land, *F*(1, 4) = 22.50, *p* = .010, and when the material was learned on land, recall memory was better when tested on land than when tested under water, *F*(1, 4) = 28.90, *p* = .007. 

For the second ANOVA on the recognition memory task data, there was no significant interaction, *F*(1, 4) = 0.42, *p* = .553.

In brief, the three-way interaction reflects the fact that recall memory is sensitive to the learning and testing context, whereas recognition memory is apparently not sensitive to such contextual factors. 

## Analysing the hypothetical data for the word pronunciation study

A researcher wants to investigate the development in children’s ability to pronounce regular and irregular words. The researcher adopts a 2 $\times$ 2 $\times$ 2 mixed design: 

* **age** (7 years old *vs.* 9 years old) is a between-participants factor

* **word frequency** (low *vs.* high) is a within-participants factor

* **word type** (regular *vs.* irregular) is also a within-participants factor

Participants are given 10 words to pronounce in each category (40 words in total) and the dependent measure of interest is the number of pronunciation errors.

The data set contains the following variables:

* **Participant:** represents the participant number, which ranges from 1--10.

* **Age:** whether the participant is 7-years-old or 9-years-old.

* **High_Regular:** pronunciation errors for high frequency regular words.

* **High_Irregular:** pronunciation errors for high frequency irregular words.

* **Low_Regular:** pronunciation errors for low frequency regular words.

* **Low_Irregular:** pronunciation errors for low frequency irregular words.

### Import data, set variables as factors, and generate descriptive statistics

The first thing you need to do is load the data into RStudio. Make sure that you name your data frame as `wordPron`. 

```{r}
# *** ENTER YOUR OWN CODE HERE TO IMPORT THE DATA ***
```

```{r, echo = FALSE, eval = FALSE}
# Import the data
wordPron = read_csv("data/wordPronunciation.csv")
(wordPron)
```

```{r, echo = FALSE, message = FALSE}
# Import the data
wordPron = read_csv("data/Wk9/wordPronunciation.csv")
(wordPron)
```

The next thing we need to do is convert our data from wide format into long format. The first thing we need to do is group the columns `High_Regular` through to `Low_Irregular` into a new variable called `Group` using the `gather()` function. We showed you how to do this in the earlier data set, so give this a go for yourself. Make sure that you name the dependent measure `Errors` and that you call your new data set `wordPronLng`.

```{r}
# *** ENTER YOUR OWN CODE HERE TO GATHER THE WITHIN-PARTICIPANTS FACTORS INTO A COMMON GROUP ***
```

If you have executed your code correct, you should see the following output:

```{r, echo = FALSE, message = FALSE}
# Gather factors into a single column
wordPronLng = wordPron %>%
  gather(Group,Errors,High_Regular:Low_Irregular,factor_key = TRUE)
(wordPronLng)
```

We have a new variable `Group` that contains our two independent variables, Frequency and Word Type, and a new variable `Errors` that contains our dependent measure. The next step is to use the `separate()` function to divide the variable `Group` into two new variables, one called `Frequency` and one called `WordType`. Again, we gave you an example of this earlier, so try your own code out for this bit. Just make sure you call your new data set `wordPronLngSep`.
  
```{r}
# *** ENTER YOUR OWN CODE HERE TO SEPARATE "GROUP" INTO SEPARATE VARIABLES FOR "FREQUENCY" AND "WORDTYPE" ***
```  

Assuming you have executed your code correctly, you should see the following output:
  
```{r, echo = FALSE, message = FALSE}
# Now separate into separate columns for each factor
wordPronLngSep = wordPronLng %>%
  separate(Group, c("Frequency","WordType"))
(wordPronLngSep)
```

Our variable `Group` has now disappeared and in its place we have two new variables: `Frequency` and `WordType`. This is the version of the data set we will be using for the rest of the analysis.

The next thing we need to do is convert the columns `Participant`, `Age`, `Frequency`, and `WordType` into factors and re-order the levels of the latter two variables:

```{r, echo = TRUE, message = FALSE}
# Make sure all necessary variables are coded as factors -- re-order the levels of "Frequency" and "WordType"
wordPronLngSep$Participant = factor(wordPronLngSep$Participant)
wordPronLngSep$Age = factor(wordPronLngSep$Age)
wordPronLngSep$Frequency = factor(wordPronLngSep$Frequency,levels = c("Low","High"))
wordPronLngSep$WordType = factor(wordPronLngSep$WordType,levels = c("Regular","Irregular"))
```

Next, we will generate some descriptive statistics (mean and standard deviation). You can generate the code for this yourself. Make sure that you round the statistics to two-decimal places using the procedure I showed you in the earlier example.

```{r}
# *** ENTER YOUR OWN CODE HERE TO GENERATE DESCRIPTIVE STATISTICS ***
```

If you have executed the code correctly, then you should see the following output:
  
```{r, echo = FALSE, message = FALSE}
# Get descriptive statistics
descriptives = wordPronLngSep %>%
  # Organise the output by the "Age", "Frequency", and "WordType" factors
  group_by(Age, Frequency, WordType) %>%
  # Request means, standard deviations, and confidence intervals
  get_summary_stats(Errors, show = c("mean", "sd"))
  # Round the statistics to two decimal places
  descriptives$mean = round(descriptives$mean, 2)
  descriptives$sd = round(descriptives$sd, 2)
  # Print the results
  print.data.frame(descriptives)
```

### Running the ANOVA, follow-up ANOVAs, and simple main effects

The code required to run the ANOVA is given below:

```{r, message = FALSE, warning = FALSE}
# Create the mixed design ANOVA model
wordPronModel = anova_test(data = wordPronLngSep, dv = Errors, wid = Participant, between = Age, within = c(Frequency, WordType), detailed = TRUE)
# Round the p values to three decimal places
wordPronModel$p = round(wordPronModel$p, 3)
# Print the model summary
(wordPronModel)
```

To create the model, the first argument we supplied to `anova_test` was the name of our data, `wordPronLngSep`. The second argument we supplied was our dependent variable, `Errors`. The third argument we supplied was `Participant`, which is the column containing the individuals/participants identifier. The fourth argument we supplied was our between-participants factor, `Age`. The fifth argument we supplied as our within-participants factors, `Frequency` and `WordType`. 

As in our first example, our factors have only two levels, so `anova_test` does not give us Mauchly's test of sphericity or the Greenhouse-Geisser correction for the within-participants factors. 

Inspecting the ANOVA table, rows two to four give the main effects of Age, Frequency, and Word Type; rows five to seven give the Age $\times$ Frequency, Age $\times$ Word Type, and Frequency $\times$ Word Type two-way interactions; and row eight gives the Age $\times$ Frequency $\times$ Word Type three-way interaction. Looking at the $p$ values, we can see that all the main effects, two-way interactions, and the three-way interaction are significant. 

Because the three-way interaction is significant, we need to analyse it further. As before, to do this we need to re-analyse the data as a series of two-factor ANOVAs. First, we must decide which factor to split the analysis by and the obvious contender is the between-participants factor of age. Accordingly, what we need to do is to perform two, two-factor ANOVAs:

1. a 2 (frequency: low *vs.* high) $\times$ 2 (word type: regular *vs.* irregular) ANOVA for the *7-year-olds* only.

1. a 2 (frequency: low *vs.* high) $\times$ 2 (word type: regular *vs.* irregular) ANOVA for the *9-year-olds* only.

We will start by running the two-factor ANOVA for the 7-year-olds (ignoring the data for the 9-year-olds). To do this, we first need to produce a filtered version of our data set called `sevenYearsOnly` that only includes the results for the 7-year-old children. We can create that with the following piece of code:

```{r, message = FALSE, warning = FALSE}
# Get the data for the "7 Year Olds" only
sevenYearsOnly = wordPronLngSep %>%
  filter(Age == "7 Year Olds") 
```

Next, we can run our two-factor ANOVA on this filtered data set. The steps are the same as above, except that we need to drop the Age factor included previously (remember, we are only analysing the data for the 7-year-olds). 

```{r, message = FALSE, warning = FALSE}
# Run the two-factor ANOVA for the "7 Year Olds" only
sevenYearsModel = anova_test(data = sevenYearsOnly, dv = Errors, wid = Participant, within = c(Frequency, WordType), detailed = TRUE)
# Round the p values to three decimal places
sevenYearsModel$p = round(sevenYearsModel$p, 3)
# Print the model summary
(sevenYearsModel)
```

The only thing we are interested in from the ANOVA table is the outcome of the two-way interaction between Frequency and Word Type; you can ignore everything else. You can see that the interaction is nonsignificant in this instance, $p$ = .405. Thus, for 7-year-old children Frequency and Word Type do not combine with one another to influence pronunciation errors.

What about 9-year-old children?

That brings us to our second two-factor ANOVA. For this, we now need to produce a filtered version of our data set called `nineYearsOnly` that only includes the results for the 9-year-old children. We can create that with the following piece of code:

```{r, message = FALSE, warning = FALSE}
nineYearsOnly = wordPronLngSep %>%
  filter(Age == "9 Year Olds") 
```

The command `filter(Age == "9 Year Olds")` tells R that we only want the data for the 9-year-old children. 

Next, we can run our two-factor ANOVA on this filtered data set.  

```{r, message = FALSE, warning = FALSE}
# Run the two-factor ANOVA for the "9 Year Olds" only
nineYearsModel = anova_test(data = nineYearsOnly, dv = Errors, wid = Participant, within = c(Frequency, WordType), detailed = TRUE)
# Round the p values to three decimal places
nineYearsModel$p = round(nineYearsModel$p, 3)
# Print the model summary
(nineYearsModel)
```

This time the interaction between Frequency and Word Type is significant, *p* = .004, so we now need to perform a simple main effects analysis to determine why.

Before we can calculate the simple main effects, there are a few things we need to do. First, we need to store our ANOVA table in a dataframe:

```{r, message=FALSE}
# Get the 9 year olds ANOVA table
nineYearsAnovaTable = get_anova_table(nineYearsModel)
```

Next, we need to calculate the cell totals for each of the four conditions and the number of observations (i.e., scores) in each cell:

```{r, message=FALSE}
# Get cell totals and counts
nineYearsCellTotals = nineYearsOnly %>%
  # Organise the output by the "Frequency" and "WordType" factors
  group_by(Frequency, WordType) %>%
  # Request cell totals and number of observations (i.e., scores)
  summarise(sum = sum(Errors),n = n())
  # Print the results
  (recallCellTotals)
```

Then, we need to specify which simple main effects we want to generate. We are first going to calculate the simple main effects of the factor Frequency at Word Type. This means, we are going to:

* Test the difference between low and high frequency *regular* words only.
* Test the difference between low and high frequency *irregular* words only.

To do this, we need to declare Frequency as the "fixed" factor (we are always comparing low and high frequency words) and Word Type as the "across" factor (the comparison between low and high frequency words occurs "across" the regular and irregular levels of the Word Type factor): 

```{r, message=FALSE}
# Create "fixed" and "across" factors
fixed  = "Frequency"
across = "WordType"
```

We then generate the simple main effects of Frequency at Word Type with the following:

```{r, message=FALSE}
# Simple main effects of "Frequency" at "WordType"
smeFrequency = simple(nineYearsCellTotals,nineYearsAnovaTable,fixed,across)
# Round the p values to three decimal places
smeFrequency$P = round(smeFrequency$P, 3)
(smeFrequency)
```

The simple main effect of Frequency at regular words is nonsignificant, $p$ = .812, indicating that pronunciation errors for regular words do not differ according to whether they are low or high in frequency. However, the simple main effect of Frequency at irregular words is significant, $p$ = .012, indicating that pronunciation errors for irregular words are higher when they are of low frequency than when they are of high frequency (check the descriptive statistics to verify this).

Now, let's calculate the simple main effects of Word Type at Frequency. This means, we are going to:

* Test the difference between regular and irregular *low* frequency words only.
* Test the difference between regular and irregular *high* frequency words only.

To do this, we need to declare Word Type as the "fixed" factor and Frequency as the "across" factor: 

```{r, message=FALSE}
# Create "fixed" and "across" factors
fixed  = "WordType"
across = "Frequency"
```

We then generate the simple main effects of Word Type at Frequency as follows:

```{r, message = FALSE, warning = FALSE}
# Simple main effects of "WordType" at "Frequency"
smeWordType = simple(nineYearsCellTotals,nineYearsAnovaTable,fixed,across)
# Round the p values to three decimal places
smeWordType$P = round(smeWordType$P, 3)
(smeWordType)
```

The simple main effect of Word Type at low frequency is significant, $p$ $<$ .001, indicating that there are more pronunciation errors for low frequency irregular words than for low frequency regular words. Second, the simple main effect of word type at high frequency is nonsignificant, $p$ = .561, indicating that pronunciation errors for high frequency regular and irregular words do not differ.

In short, the three-way interaction arose because pronunciation errors in 7-year-old children are unaffected by word frequency and word type, whereas pronunciation errors in 9-year-old children are influenced by these factors. Specifically, low frequency irregular words are associated with more pronunciation errors than low frequency regular words, but there is no difference between the frequency of pronunciation errors for high frequency irregular and regular words. This pattern can be seen in Figure 2 below which plots the data for the word pronunciation study.

![Figure 2. Pronunciation errors as a function of word frequency and word type for 7-year-old children (left panel) and 9-year-old children (right panel).](images/WordPronunciationDatax.png){width=75%}

### Writing up the results

The conventions for writing up the results of a mixed three-factor ANOVA are the same as for a fully within-participants three-factor ANOVA (and indeed a fully between-participants three-factor ANOVA), so see my example write-up for the memory and context study. 

<!-- Why don't you have a go at writing up these results? I'll give an example write-up when I post the instructor's copy of the materials online at the end of the week. -->

### Additional tasks
Phew!! That's probably the most we have covered in any of our lab sessions. Well done for making it through to the end! 

Here are some additional tasks you might consider doing:

* Write-up the results of the word pronunciation study.
* Generate the interaction plots in Figures 1 and 2, but add error bars (confidence intervals) to the data points.

I'll include the write-up/plot code for these additional tasks in the instructors copy of the lab materials at the end of the week.

<br>
<br>
<br>
<br>
---
title: 1. Measurement, Variance and Inferential Statistics
subtitle: "Richard Philpot, Mark Hurlstone"
order: 2
---

# Lecture

Watch Part 1 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981602)

Watch Part 2 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981612)

Watch Part 3 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981614)

Watch Part 4 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981618)

Watch Part 5 [here](https://modules.lancaster.ac.uk/mod/panopto/view.php?id=1981621)

Download the lecture slides [here](data/Wk1/Lecture 1 - Student Slides.pdf), and [here](data/Wk1/Psyc214 - Lecture 1 Week 1 - Student Slides [large].pdf) for a larger version.

# Lab

Welcome back to Lancaster University and congratulations on your progression to Year 2!


This will be the first lab session for Psyc214 - Statistics for Psychologists. In these lab sessions you will work from sheets (like this one) which detail activities and provide hands on experience of working and problem solving in R. At times these sheets will offer step-by-step instructions of how to wrangle data and to run a relevant command or analysis. At other times, and to reinforce learning, you will be asked to 'fill in the gaps' yourselves or to rewrite the code to solve a new problem. Myself (Richard Philpot), Mark Hurlstone and an apt team of GTAs will be on hand to help you through this journey - so please do not panic - you're never alone. In Psyc214, we also encourage peer engagment and joined problem solving - so please do not hesitate to ask for help from another on your table or to work together in small groups. Right, that enough for now, so let's get started!ðŸ’ª
  
******
## 1 - General Introduction

| *"Once more unto the breach, dear friends, once more"* | King Henry V, by William Shakespeare.

![Fifty shades of rust](https://images.pexels.com/photos/1301413/pexels-photo-1301413.jpeg?cs=srgb&dl=pexels-magda-ehlers-1301413.jpg&fm=jpg)

The formation of rust can occur quickly and within minutes or slowly, over many years. It all depends on the material that is rusting, it's lack of use and the environment!

In this analogy, let's consider our 'R brains' as the material vulnerable to rusting. With individual differences, some of us may remember more of last year's statistic course than others - and that's completely normal.

When considering repeated use and our environments, it is also unlikely that many of us have interacted with R and statistics over the intervening summer months. Quite sensibly we've enjoyed a non-academic environment - holidays, summer jobs, commitments to family and friends, these are all important things that have rightly taken priority!


It therefore an entirely natural process for folks to feel rusty and hesitant when re-engaging with R and statistics. As such, in this first session, let's get re-accustomed with our old friend 'R'.


  
******
### 1.1 Access to R Studio

You will recall from last year that R Studio is a free, open-source data science engine that works as a giant calculator on steroids. Beyond number crunching, R studio allows you to organise your data, construct beautiful tables and graphs, as well as document your code and findings for others to inspect.

![Vintage computational power and R Studio](https://images.unsplash.com/photo-1607370883617-9720ac853cc4?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1650&q=80)

{{< include /Includes/_login.qmd >}}

******
### 1.2 Creating a folder for today's session

Once you are logged into the server, create a folder for todayâ€™s session. This will be where we will house today's data and script. This will allow you to save you store your work and return at a later date (for example, around exam time - wink wink)

Navigate to the bottom right panel (see figure below) and click Home. Next, under the Files option select the New Folder option. Name the new folder psyc214_lab_1. Please ensure that you spell this correctly otherwise when you set the directory using the command given below it will return an error.

![Creating a folder on your server](images/Lab1_folder.png)


******
### 1.3 Uploading today's data file and creating a script

Now that you have created a folder for todayâ€™s session, itâ€™s time to add the Week 1 data file. You can download the file from [here](data/Wk1/week1_robo_lab.csv). 

Next, in the RStudio Server open your new psyc214_lab_1 folder. When in the new folder, select the Upload tab (see figure below). This will present a box that will ask where the data is that you want to upload. Click on Browse, find the `week1_robo_lab.csv` file on your desktop and click OK.


![Uploading today's data](images/Lab1_upload_files.png)

So we can save this session on the server, click File on the top ribbon and select New project. Next, select existing directory and name the working directory `~/psyc213_lab_1` before selecting create project.

Finally, open a script for executing todayâ€™s coding exercises. Navigate to the top left pane of RStudio, select File -> New File -> R Script. Working from a script will make it easier to edit your code and you will be able to save your work for a later date.

![Creating a script](images/Lab1_script.png)

**Be sure to save the script using the File -> Save As....**

******
### 1.4 Setting the working directory and opening the data file

A working directory is the default location or folder on your computer/server by which R will read/save any files. It can be set with the following R code:

```{r eval = FALSE}
  setwd("/PSYC214")
```

```{r eval = FALSE}
setwd("~/psyc214_lab_1")
```

Now you've downloaded the data and set the working directory it's time to open the data file in R studio. To do this, please type the following code:
  
```{r, eval=FALSE}
lab1_data <- read.csv("week1_robo_lab.csv")
```

```{r, echo=FALSE}
lab1_data <- read.csv("data/Wk1/week1_robo_lab.csv")
```
  
  where 'lab1_data' is the name we've assigned that R will recognise when it calls up our data, 'read.csv' is the R command to pull up the data and 'week1_robo_lab.csv' is the name of the original data file you downloaded and stored.

*Note. During the rest of this session, you will not need to refer to the original downloaded .csv data file. R has all the information stored under the â€˜lab1_dataâ€™ variable. Further note, you could have called â€˜lab1_dataâ€™ by pretty much any name you likeâ€¦ â€˜df1â€™, â€˜robo_1', â€˜I.love.stats.comâ€™, etc. - the name is somewhat arbitrary. For the purpose of this lab session and for ease of read, â€˜lab1_dataâ€™, is perhaps more suitable.*
  
******
### 1.5 loading the relevant library  
  
Finally, letâ€™s load the relevant libraries that we will be using in todayâ€™s session:

```{r message=FALSE}
library(tidyverse)
library(rstatix)
library(ggpubr)
```

------ 
## 2 - Today's lab activities 

Now that you have loaded the dataset, let's have a play.


### 2.1 Some background information about the dataset

![Introducing the robo-lab study](https://images.pexels.com/photos/8386434/pexels-photo-8386434.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260)

In this lab session, we will examine the fictitious 'robo_lab' dataset.
Here, a team of researchers wanted to know whether LU statistics students would respond well to a new, ambitious initiative to deploy a team of synthetic robots as lab assistants.
  
******
### 2.2 Study manipulation

The research team developed two robot prototypes and wanted to test which prototype would be optimal for classroom teaching. 
In a controlled experiment, the researchers randomly assigned groups of students either Robot A(lpha) or Robot B(eta). Note this is one factor design (Robot assignment) made of two levels (Robot A or Robot B).

Those individuals assigned Robot A(lpha) were denoted as belonging to 'Group A'.
\
Those individuals assigned Robot B(eta) were denoted as belonging to 'Group B'.
\
Note. The groups are mutually exclusively - i.e., a participant was assigned to either Group A/Robot A or Group B/Robot B, not both.

![**Robot A(lpha)**](images/Wk1/RobotA.png)

![**Robot B(eta)**](https://images.pexels.com/photos/2599244/pexels-photo-2599244.jpeg?auto=compress&cs=tinysrgb&h=750&w=1260)
  
******
### 2.3 Dependent (a.k.a. Outcome) variables

Next, the researchers required some outcome measures to evaluate whether indeed the students had responded more positively toward one robot prototype over another.

The research team settled on two dependent variables (or outcome measures). These measured student stats competence (something important!) and attitudes towards teaching support (something also very important!).

DV1: Student stats competence was measured by a Psyc214 test score; ranging between 40-100.

DV2: Student attitudes towards the robot lab assistant was assessed with a likert scale response between 1-7; with 1 = 'strongly dislike' and 7 = 'strongly like'.
  
******
### 2.4 Predictions of the research team

The research team had their own expectations for which robot would be best received by students.
Specifically, they predicted that:

- Individuals assigned Robot B(eta) would score significantly higher in their Psyc214 tests (Hypothesis 1)

- Robot B(eta) would be significantly more liked than Robot(A)lpha (Hypothesis 2)

The researchers expected that this difference would be explained by Robot B(eta)'s closer resemblance to other human beings. Indeed, prior to the study, independent raters had reliably agreed that Robot B(eta) resembled a human being significantly more than Robot A(lpha).
  
******
### 2.5 Refamiliarising with some basic features
Now that you have opened the dataset and are aware of what the different variables for this study are, it's time to explore.

In this first refresher session, we will be refamiliarising ourselves with some of the key functions and features learned in last year stats classes. 

Earlier, we loaded the package `dplyr`, which is readily accessible from the `tidyverse` collection. This package allows us to use some nifty functions such as:

- pipes `%>%`  
- `arrange()`
- `summary()`
- `sd()`
- IQR, etc.
  
******
### 2.6 Examining and ordering data

Now that we have our pieces in play, let's take a look at the data.

We first want to get a brief overview of what the data set looks like. 
To do this, we use the use the `head()` command, which displays the first rows present in the data frame.

To view these first rows, please apply the following code:

```{r}
  head(lab1_data)
```

This shows us the first 6 rows. Note, while the default is six, you can also specify the number of rows as follows - please try it out.

```{r, results = FALSE}
  head(lab1_data, n=12)
```

Great. We can now see the first 12 rows of data. 
One thing that is noticeable, however, is that the data are ordered by participant 'ID'. Say we want to get an overview of our data where we can see data ordered by the from lowest Psyc214 test score to highest. We can arrange data this way using the `arrange()` command, were we include 'Score' as the variable of interest. Please try the following:

```{r}
  lab1_data %>% arrange(Score)
``` 

You will note that the command outputs 100+ data rows showing the values of over 100 of our participants.

This can be quite a whooper!

If we want to make this output more manageable we could always add an additional `>%>` pipe command which combines both arrange and head.

For example the code below, combining `arrange()` and `head()` allows us order the data based on lowest score and then to display *only* the top 10 results. 

```{r}
  lab1_data %>% arrange(Score) %>% head(n=10)
``` 

Phew. This is more manageable.

This table provides some interesting information. We can see that the lowest scores were 40, which was the bottom cutoff point of our measurement scale. 

A quick eyeballing of the data rows suggests the lowest 10 test scores predominately have participants who were assigned to Group A(lpha). In fact, 9 out of 10 of the lowest scores belonged to individuals from Group A.

It would also be prudent to check the top 10 highest scores and to get a feel for what the top marks were like. We can again order our data using the `arrange()` function. This time however, we add the term `arrange(desc())` to show that we are asking R for descending ordering.

Please try the following command to examine the top scorers
```{r, results = FALSE}
  lab1_data %>% arrange(desc(Score))
```

You will note in your own output, that the scores are once again showing over 100 values!

To make this more manageable, please try writing your own code combining the `arrange(desc())` command, a pipe `%>%` and the `head(n = x)` command. If stuck, refer to the command we used higher up.

```{r}
#ANSWER CODE
lab1_data %>% arrange(desc(Score)) %>% head(n=10)
```

You now should have an output of descending scores which are more manageable.

```{r echo = FALSE}
lab1_data %>% arrange(desc(Score)) %>% head(n=10)
```

Try eyeballing these scores and group IDs to see whether the higher scores tend to be associated with one group over another. Any thoughts?
  
******
### 2.7 Assessing the descriptives

As of yet, we have not examined the basic descriptive statistics of our data, so let's take a look now.

We can compute the minimum and maximum values, 1st and 3rd quartiles, median and mean all at once using the `summary()` command:

```{r}
summary(lab1_data)
```

There are still a number of descriptives which may be interesting, but that the `summary()` function does not provide, however.

For example, we may be interested in ... (remember from last lecture ;) ...:

- the range of our data points (i.e., the difference between the lowest and highest values)
- the interquartile range of data (i.e., the difference between the first and third quartiles) 
- the standard deviation (i.e.,  the dispersion of a dataset relative to its mean, that being the square root of the variance)

These can all be calculated relatively easily with the following commands:

- the range of our data points: `range()`
- the interquartile range: `IQR()`
- the standard deviation: `sd()`

```{r}
range(lab1_data$Score)
IQR(lab1_data$Score)
sd(lab1_data$Score)
```

Note that this only provides the information for the 'Scores' dependent variable - I.e., DV1.

We do not know what the respective values are for the 'Likeability' dependent variable (DV2).

If we want to examine multiple variables simultaneously, we can use the `sapply()` function, which can take multiple lists/vector/data frames as inputs within a single command. Nifty.

Here, we need to specify which columns we would like to assess. In our data the 'Scores' dependent variable (DV1) and 'Likeability' dependent variable (DV2) are columns 4 and 3 of the datasheet, respectively.

Let's try in with the range.

```{r}
sapply(lab1_data[, 4:3], range)
```

Here we see that the range in Psyc214 test scores (i.e., the min and max scores in the cohort of all participants) ranged between 40 and 88.

Also, the min and max ratings for the likeability scores were between 0 and 7, respectively.

Now, please try to apply the code above yourself, but change 'range' with the standard deviation 'sd' function to get the standard deviation for both the score and likeability variables simultaneously.

```{r}
#ANSWER CODE
sapply(lab1_data[, 4:3], sd)
```

If done correctly, you should received the following output:
```{r, echo=FALSE}
sapply(lab1_data[, 4:3], sd)
```

  
******
### 2.8 Descriptives by group condition

Now that we have some information regarding the overall data, we can rejoice.

Well only briefly...

Although this information is useful, it gives information regarding all data points and does not generate these values based on the two assigned independent groups - i.e., the two levels (Group Robot A, Group Robot B) of our single factor (Robot Assignment).

Although there are work arounds for this, simpler functions are available in the rstatix() package (previously loaded).

Using the package's `group_by()` command and pipes `%>%` we can ask R to separate our data based on the group assigned. Note, here the name of the grouping variable for our dataset is 'Group'.

Let's ask for the mean for our two groups with the following command. 
First we tell R we are using the lab1_data. Then we say within this data set we want to separate the data by the 'Group' variable. Finally we ask for summary stats for the DV1 the Score. We will ask only for the mean.
  
```{r}
  lab1_data %>%
  group_by(Group) %>%
  get_summary_stats(Score, type = "mean")
```

Great. Now let's do the same again, but this time we will ask for summary statistics for both the Score (DV1) and Likeability (DV2) variables. Furthermore, let's also ask for the sd, min, max and iqr.

```{r}
  lab1_data %>%
  group_by(Group) %>%
  get_summary_stats(Score, Likeability, show = c("mean", "sd", "min", "max", "iqr"))
```

Ok, perfect. This now tells us a lot of information. For example, we can see that the mean test scores for Group A and B are 56.6 and 62.8 respectively. On reflection, and considering the importance of getting a nice score, these means do seem quite different from one another. 
  
******

## 3. And more

### 3.1 Visualising data

As a next step, let's plot the data and see the distribution of data points in visual form. To do this, we've already loaded the excellent data visualization package `ggpubr`.

To plot the data we use the `ggboxplot()` command.
First we are required to say what dataset we'll be using, which is again 'lab1_data'. Next we type 'main=' to specify the title for the plot. Let's call the plot "Box plot of test scores by robot condition". We then need to specify what data we would like to use for each axis. For the x-axis we would like to plot the different groups, so let's add x = "Group". Our y-axis will be the "Score". We can colour the groups also and add shapes to data points. Finally, let's give the x-axis and y-axis each a descriptive label. "Robot group condition" and "Psyc214 test score" seem appropriate here.

```{r}
  # Box plot of test scores by Robot Condition
ggboxplot(lab1_data,main="Box plot of test scores by robot condition", 
               x = "Group", y = "Score", #variables for axes
                color = "Group", palette =c("#999999", "#333333"), #colour of data
                add = "jitter", shape = "Group", # shape of data
               xlab="Robot group condition", ylab="Psyc214 test score") #labels for axes
```

Observing the spread of data points for Group A and B, respectively, we can see trends in which Group B tends to have more data points clustered higher on the test score axis than Group A. Group A has more data points clustered lower on the test score axis than Group B and these distributions are reflected by the boxplots. Again it seems we have a signficant difference, but we will need a statistical test to be certain.
  
******
### 3.2 Independent 2-group T-test

To get to the bottom of this we need to perform an independent 2-group t-test. This inferential statistical test is appropriate when you want to examine whether there are any statistically significant differences between the means of two unrelated groups. This can be run using the `t_test()` function, where 'Score' is our y (dependent variable) and 'Group' is our predictive factor x (independent variable).

```{r}
# independent 2-group t-test
  #t_test(Score ~ Group) # where y is numeric Score and x is a binary factor 
# Compute t-test
 t.test(formula = Score ~ Group, pool.sd = FALSE, var.equal = TRUE, data = lab1_data)
```

The output provides the t-value and itâ€™s 95% confidence interval - i.e., we can be 95% certain that the true value of t falls within the the lower and upper confidence intervals. We also get the means of our groups, the degrees of freedom for our t-test and the p-value. 
This p-value is significantly lower than 0.05 meaning that we reject the null hypothesis - i.e., we accept that the true difference is not roughly equal to zero. As such, there is a statistical difference in Psyc214 assessment scores between the two groups. What we are yet to discover is whether this represents a small, moderate or large effect.

To calculate the effect size, where 0.2 = small effect, 0.5 = moderate effect, 0.8 = large effect (Cohen, 1988), we use the 'cohens_d()' function.

```{r}
  # Cohen's d effect size calculation
cohens_d(Score ~ Group,  # Formula
       data = lab1_data) # Dataframe containing the variables
```

This output shows us that we have a moderate negative effect of -0.62 ; note. it is negative because of the order of our factors - i.e., Group A (which is presented first in our equation) has a lower set of scores than Group B. As you typically report the effect size as a value between 0-1 we need to treat the result as an absolute value, meaning we ignore the minus symbol when reporting our results.
  
******
### 3.3 Reporting the results of the independent 2-group T-test in APA format

All results should be written up in accordance with the American Psychological Association's (APA) guidance. This ensures that your results are easy to interpret and that all the relevant information is present for those wishing to review/replicate your work.

The current results can be reported as following:
"An independent 2-group T-test was carried out to examine whether there were statistical differences in the Psyc214 assessment scores between those students assigned Robot A(lpha) and those assigned Robot B(eta). This test was found to be statistically significant, *t*(198)= -4.42, 95% CI [-8.90, -3.40], *p* < .001, *d* = 0.62. This effect size represents a moderate effect (Cohen, 1988). These results indicate that individuals assigned Robot A(lpha) (*M* = 56.61, *SD* = 9.05) typically received lower Psyc214 assessment scores than those individuals assigned Robot B(eta) (*M* = 62.76, *SD* = 10.60)"
  
******
## 4. Further tasks

1. repeat the steps in '2.8 Descriptives by group condition', this time examining the summary statistics for our second dependent variable - 'Likeability'.

```{r}
  #ANSWER CODE
  lab1_data %>%
  group_by(Group) %>%
  get_summary_stats(Likeability, type = "mean")
```

2. repeat the steps in '3.1 Visualising data', this time creating box plots for our second dependent variable - 'Likeability'. Rename the title and axes to something more suitable and perhaps even change the colour of data points. Describe the trends in data to a classmate or your inner self.

```{r}
#ANSWER CODE
  # Box plot of likeability scores by Robot Condition
ggboxplot(lab1_data,main="Box plot of test scores by robot condition", 
               x = "Group", y = "Likeability", #variables for axes
                color = "Group", palette =c("#999999", "#333333"), #colour of data
                add = "jitter", shape = "Group", # shape of data
               xlab="Robot group condition", ylab="Likeability scores") #labels for axes
```

3. compute an independent t-test (steps 3.2) to examine whether there are any statistical differences between the means of our two groups in their Likeability ratings. Write up the results in APA style.

```{r}
#ANSWER CODE
# independent 2-group t-test
  #t_test(Score ~ Group) # where y is numeric Score and x is a binary factor 
# Compute t-test
 t.test(formula = Likeability ~ Group, pool.sd = FALSE, var.equal = TRUE, data = lab1_data)

  # Cohen's d effect size calculation
cohens_d(Likeability ~ Group,  # Formula
       data = lab1_data) # Dataframe containing the variables
```

4. before you finish, make sure you save a copy of the script that you have been working on by the end of the session. This provides you with the record - the digital trace - on what you have done. And it means you can come back and repeat any of the work you have performed.

Please end your session on the RStudio server, this logs you out of the server and stops any ongoing activities and tasks you have set up, maybe in the background.

![Ending session on R Studio](https://tombeesley.github.io/PSYC121_2022-23/files/Week_1/power_button.png)

5. ...

Now breathe! You've rocked it!!!

![Top work!](https://images.unsplash.com/photo-1536193533103-5bb31b6fb667?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1170&q=80)


# Lab Feedback (voluntary)

This is a voluntary, super fast [survey](https://modules.lancaster.ac.uk/mod/url/view.php?id=1905311), just to gauge how you found the difficulty of the content and any additional feedback.